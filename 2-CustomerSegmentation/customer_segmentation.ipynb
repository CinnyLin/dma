{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Import module ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Define functions ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(n_clusters_f, init_f, df_f):\n",
    "    # Complete this function\n",
    "    # This function should at least take a dataframe as an argument. I have suggested additional arguments you may\n",
    "    # want to provide, but these can be changed as you need to fit your solution.\n",
    "    # The output of this function should be the input data frame will the model object KMeans and a data summary. The\n",
    "    # function will need to add an additional column to the input dataframe called 'predict_cluster_kmeans'\n",
    "    # that contains the cluster labels assigned by the algorithm.\n",
    "    k_means_model_f = KMeans(n_clusters=n_clusters_f, init=init_f)\n",
    "    k_means_model_f.fit(df_f)\n",
    "    df_f['predict_cluster_kmeans'] = k_means_model_f.labels_\n",
    "\n",
    "    # summarize cluster attributes\n",
    "    k_means_model_f_summary = df_f.groupby(\n",
    "        'predict_cluster_kmeans').agg(attribute_summary_method_dict)\n",
    "    return k_means_model_f, k_means_model_f_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(timestamp):\n",
    "    return int(timestamp.split()[1].split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- set parameters\n",
    "n_clusters = 3\n",
    "init_point_selection_method = 'k-means++'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_summary_method_dict = {'burger': np.mean, 'fries': np.mean, 'salad': np.mean, 'shake': np.mean, 'hour': np.mean, 'store_1': sum,\n",
    "                                 'store_4': sum, 'store_6': sum, 'store_3': sum, 'store_9': sum, 'store_2': sum, 'store_8': sum, 'store_5': sum, 'store_7': sum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df[['burger', 'fries', 'salad', 'shake', 'hour', 'store_1', 'store_2', 'store_3', 'store_4',\n",
    "       'store_5', 'store_6', 'store_7', 'store_8', 'store_9']]\n",
    "\n",
    "model = KMeans(3)\n",
    "model.fit(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-cfa1cc027db3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['predict_cluster_kmeans'] = model.labels_\n"
     ]
    }
   ],
   "source": [
    "test_df['predict_cluster_kmeans'] = model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>burger</th>\n",
       "      <th>fries</th>\n",
       "      <th>salad</th>\n",
       "      <th>shake</th>\n",
       "      <th>hour</th>\n",
       "      <th>store_1</th>\n",
       "      <th>store_4</th>\n",
       "      <th>store_6</th>\n",
       "      <th>store_3</th>\n",
       "      <th>store_9</th>\n",
       "      <th>store_2</th>\n",
       "      <th>store_8</th>\n",
       "      <th>store_5</th>\n",
       "      <th>store_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict_cluster_kmeans</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345463</td>\n",
       "      <td>2.234386</td>\n",
       "      <td>1.888923</td>\n",
       "      <td>0.118537</td>\n",
       "      <td>12.222068</td>\n",
       "      <td>4521.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>917.0</td>\n",
       "      <td>4577.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>4660.0</td>\n",
       "      <td>4491.0</td>\n",
       "      <td>968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.185515</td>\n",
       "      <td>3.385679</td>\n",
       "      <td>0.200057</td>\n",
       "      <td>2.831993</td>\n",
       "      <td>18.741487</td>\n",
       "      <td>928.0</td>\n",
       "      <td>6496.0</td>\n",
       "      <td>2306.0</td>\n",
       "      <td>977.0</td>\n",
       "      <td>6554.0</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>867.0</td>\n",
       "      <td>6509.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.733254</td>\n",
       "      <td>1.789796</td>\n",
       "      <td>0.056542</td>\n",
       "      <td>0.323736</td>\n",
       "      <td>0.187528</td>\n",
       "      <td>626.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>7985.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>651.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>579.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          burger     fries     salad     shake       hour  \\\n",
       "predict_cluster_kmeans                                                      \n",
       "0                       0.345463  2.234386  1.888923  0.118537  12.222068   \n",
       "1                       3.185515  3.385679  0.200057  2.831993  18.741487   \n",
       "2                       1.733254  1.789796  0.056542  0.323736   0.187528   \n",
       "\n",
       "                        store_1  store_4  store_6  store_3  store_9  store_2  \\\n",
       "predict_cluster_kmeans                                                         \n",
       "0                        4521.0    971.0    917.0   4577.0    993.0    958.0   \n",
       "1                         928.0   6496.0   2306.0    977.0   6554.0   2188.0   \n",
       "2                         626.0    594.0   7985.0    609.0    639.0   7978.0   \n",
       "\n",
       "                        store_8  store_5  store_7  \n",
       "predict_cluster_kmeans                             \n",
       "0                        4660.0   4491.0    968.0  \n",
       "1                        1162.0    867.0   6509.0  \n",
       "2                         651.0    448.0    579.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby('predict_cluster_kmeans').agg(attribute_summary_method_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticket_id', 'burger', 'fries', 'salad', 'shake', 'location',\n",
       "       'order_timestamp', 'hour', 'store_1', 'store_2', 'store_3', 'store_4',\n",
       "       'store_5', 'store_6', 'store_7', 'store_8', 'store_9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Import data ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_count</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x209277</td>\n",
       "      <td>2019/3/2 19:59</td>\n",
       "      <td>8</td>\n",
       "      <td>shake</td>\n",
       "      <td>3</td>\n",
       "      <td>41.894202</td>\n",
       "      <td>-87.620965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x209277</td>\n",
       "      <td>2019/3/2 19:59</td>\n",
       "      <td>8</td>\n",
       "      <td>burger</td>\n",
       "      <td>4</td>\n",
       "      <td>41.894202</td>\n",
       "      <td>-87.620965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x209277</td>\n",
       "      <td>2019/3/2 19:59</td>\n",
       "      <td>8</td>\n",
       "      <td>fries</td>\n",
       "      <td>4</td>\n",
       "      <td>41.894202</td>\n",
       "      <td>-87.620965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x30b900</td>\n",
       "      <td>2019/3/26 18:06</td>\n",
       "      <td>1</td>\n",
       "      <td>shake</td>\n",
       "      <td>3</td>\n",
       "      <td>41.880844</td>\n",
       "      <td>-87.630524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x30b900</td>\n",
       "      <td>2019/3/26 18:06</td>\n",
       "      <td>1</td>\n",
       "      <td>burger</td>\n",
       "      <td>3</td>\n",
       "      <td>41.880844</td>\n",
       "      <td>-87.630524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket_id  order_timestamp  location item_name  item_count        lat  \\\n",
       "0  0x209277   2019/3/2 19:59         8     shake           3  41.894202   \n",
       "1  0x209277   2019/3/2 19:59         8    burger           4  41.894202   \n",
       "2  0x209277   2019/3/2 19:59         8     fries           4  41.894202   \n",
       "3  0x30b900  2019/3/26 18:06         1     shake           3  41.880844   \n",
       "4  0x30b900  2019/3/26 18:06         1    burger           3  41.880844   \n",
       "\n",
       "        long  \n",
       "0 -87.620965  \n",
       "1 -87.620965  \n",
       "2 -87.620965  \n",
       "3 -87.630524  \n",
       "4 -87.630524  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_csv('transactions_n100000.csv')\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185452, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Engineer features -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- convert from long to wide\n",
    "df = df_transactions.pivot(\n",
    "    index='ticket_id', columns='item_name', values='item_count').fillna(0)\n",
    "df_transactions.reset_index(inplace=True)\n",
    "df_transactions.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add back date and location\n",
    "df = df.merge(df_transactions[['ticket_id', 'location', 'order_timestamp']\n",
    "                              ].drop_duplicates(), how='left', on='ticket_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- extract hour of day from datetime\n",
    "df['hour'] = df['order_timestamp'].apply(get_hour)\n",
    "#df['hour'] = df['order_timestamp'].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- convert categorical store variables to dummies\n",
    "# use sklearn.preprocessing.OneHotEncoder() to create a class object called encoded_data\n",
    "encoded_data = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WHAT SHOULD I FIT HERE? \n",
    "\n",
    "# call the method used to fit data for a OneHotEncorder object.\n",
    "# Note: you will have to reshape data from a column of the data frame.\n",
    "# useful functions may be DataFrame methods .to_list(), .reshape(), and .shape()\n",
    "encoded_data.fit(X=np.array(df['location'].tolist()).reshape(df.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed split to regex because not all are 'x0_'\n",
    "col_map_store_binary = dict(zip(list(encoded_data.get_feature_names()), [\n",
    "    'store_' + re.split('x\\d_', x)[1] for x in encoded_data.get_feature_names()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for x in encoded_data.get_feature_names():`\n",
    "\n",
    "    try:\n",
    "\n",
    "        x.split('x0_')[1]\n",
    "\n",
    "    except:\n",
    "\n",
    "        #print(x.split('x0_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix transform data\n",
    "df_store_binary = pd.DataFrame(\n",
    "    encoded_data.fit_transform(df[['location']]).toarray())\n",
    "# df_store_binary = pd.DataFrame(encoded_data.transform(\n",
    "#    X=np.array(df['location'].tolist()).reshape(df.shape[0], 1)))\n",
    "#df_store_binary.head()\n",
    "df_store_binary.columns = encoded_data.get_feature_names()\n",
    "df_store_binary.rename(columns=col_map_store_binary, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_store_binary], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ RUN CLUSTERING -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- set parameters\n",
    "n_clusters = 3\n",
    "init_point_selection_method = 'k-means++'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- select data\n",
    "# specify list of attributes on which to base clusters\n",
    "cols_for_clustering = ['hour', 'location']\n",
    "\n",
    "# use reindex because loc list is deprecated\n",
    "df_cluster = df.reindex(columns=cols_for_clustering)\n",
    "#df_cluster = df.loc[:, cols_for_clustering]\n",
    "\n",
    "#df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- split to test and train\n",
    "df_cluster_train, df_cluster_test, _, _, = train_test_split(\n",
    "    df_cluster, [1]*df_cluster.shape[0], test_size=0.33)   # ignoring y values for unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fit model\n",
    "attribute_summary_method_dict = {'burger': np.mean, 'fries': np.mean, 'salad': np.mean, 'shake': np.mean, 'hour': np.mean, 'store_1': sum,\n",
    "                                 'store_4': sum, 'store_6': sum, 'store_3': sum, 'store_9': sum, 'store_2': sum, 'store_8': sum, 'store_5': sum, 'store_7': sum}\n",
    "col_output_order = ['burger', 'fries', 'salad', 'shake', 'hour', 'store_1', 'store_2', 'store_3', 'store_4',\n",
    "                    'store_5', 'store_6', 'store_7', 'store_8', 'store_9']  # specify order of output columns for easy of readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SpecificationError",
     "evalue": "nested renamer is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSpecificationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bc68771c308c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_model, train_model_summary = run_kmeans(\n\u001b[0m\u001b[1;32m      3\u001b[0m     n_clusters, init_point_selection_method, df_cluster_train.reindex())\n",
      "\u001b[0;32m<ipython-input-2-d2825be04281>\u001b[0m in \u001b[0;36mrun_kmeans\u001b[0;34m(n_clusters_f, init_f, df_f)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# summarize cluster attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     k_means_model_f_summary = df_f.groupby(\n\u001b[0m\u001b[1;32m     14\u001b[0m         'predict_cluster_kmeans').agg(attribute_summary_method_dict)\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mk_means_model_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_means_model_f_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 ) != len(keys):\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nested renamer is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSpecificationError\u001b[0m: nested renamer is not supported"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train_model, train_model_summary = run_kmeans(\n",
    "    n_clusters, init_point_selection_method, df_cluster_train.reindex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "test_model, test_model_summary = run_kmeans(\n",
    "    n_clusters, init_point_selection_method, df_cluster_test.reindex())\n",
    "# all data\n",
    "model, model_summary = run_kmeans(\n",
    "    n_clusters, init_point_selection_method, df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- run for various number of clusters\n",
    "# add the code to run the clustering algorithm for various numbers of clusters\n",
    "ks = range(1, 16)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k, n_init=10)\n",
    "    model.fit(df_cluster)\n",
    "    inertias.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- draw elbow plot\n",
    "# create an elbow plot for your numbers of clusters in previous step\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- output tagged data for examination ----\n",
    "store_col_names = ['store_1', 'store_2', 'store_3', 'store_4',\n",
    "                   'store_5', 'store_6', 'store_7', 'store_8', 'store_9']\n",
    "df_cluster['store'] = None\n",
    "for t_col in store_col_names:\n",
    "    df_cluster.loc[df_cluster[t_col] == 1, 'store'] = t_col.split('_')[1]\n",
    "\n",
    "df_cluster.to_csv('clustering_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cluster mode to location\n",
    "t_df = df_cluster.groupby('store')['predict_cluster_kmeans'].apply(\n",
    "    lambda x: x.mode()).reset_index()[['store', 'predict_cluster_kmeans']]\n",
    "df_transactions[['location', 'lat', 'long']].drop_duplicates().merge(\n",
    "    t_df, how='left', left_on='location', right_on='store').to_csv('store_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df['location'].tolist()).reshape(df.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['location'].tolist()).reshape(df.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit0209044da7c742dab8314e0953beb93b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Import module ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Define functions ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(n_clusters_f, init_f, df_f):\n",
    "    # Complete this function\n",
    "    # This function should at least take a dataframe as an argument. I have suggested additional arguments you may\n",
    "    # want to provide, but these can be changed as you need to fit your solution.\n",
    "    # The output of this function should be the input data frame will the model object KMeans and a data summary. The\n",
    "    # function will need to add an additional column to the input dataframe called 'predict_cluster_kmeans'\n",
    "    # that contains the cluster labels assigned by the algorithm.\n",
    "    k_means_model_f = KMeans(n_clusters=n_clusters_f, init=init_f)\n",
    "    k_means_model_f.fit(df_f)\n",
    "    df_f['predict_cluster_kmeans'] = k_means_model_f.labels_\n",
    "\n",
    "    # summarize cluster attributes\n",
    "    k_means_model_f_summary = df_f.groupby(\n",
    "        'predict_cluster_kmeans').agg(attribute_summary_method_dict)\n",
    "    return k_means_model_f, k_means_model_f_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour(timestamp):\n",
    "    return int(timestamp.split()[1].split(':')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Import data ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>order_timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_count</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x209277</td>\n",
       "      <td>2019/3/2 19:59</td>\n",
       "      <td>8</td>\n",
       "      <td>shake</td>\n",
       "      <td>3</td>\n",
       "      <td>41.894202</td>\n",
       "      <td>-87.620965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x209277</td>\n",
       "      <td>2019/3/2 19:59</td>\n",
       "      <td>8</td>\n",
       "      <td>burger</td>\n",
       "      <td>4</td>\n",
       "      <td>41.894202</td>\n",
       "      <td>-87.620965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x209277</td>\n",
       "      <td>2019/3/2 19:59</td>\n",
       "      <td>8</td>\n",
       "      <td>fries</td>\n",
       "      <td>4</td>\n",
       "      <td>41.894202</td>\n",
       "      <td>-87.620965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x30b900</td>\n",
       "      <td>2019/3/26 18:06</td>\n",
       "      <td>1</td>\n",
       "      <td>shake</td>\n",
       "      <td>3</td>\n",
       "      <td>41.880844</td>\n",
       "      <td>-87.630524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x30b900</td>\n",
       "      <td>2019/3/26 18:06</td>\n",
       "      <td>1</td>\n",
       "      <td>burger</td>\n",
       "      <td>3</td>\n",
       "      <td>41.880844</td>\n",
       "      <td>-87.630524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticket_id  order_timestamp  location item_name  item_count        lat  \\\n",
       "0  0x209277   2019/3/2 19:59         8     shake           3  41.894202   \n",
       "1  0x209277   2019/3/2 19:59         8    burger           4  41.894202   \n",
       "2  0x209277   2019/3/2 19:59         8     fries           4  41.894202   \n",
       "3  0x30b900  2019/3/26 18:06         1     shake           3  41.880844   \n",
       "4  0x30b900  2019/3/26 18:06         1    burger           3  41.880844   \n",
       "\n",
       "        long  \n",
       "0 -87.620965  \n",
       "1 -87.620965  \n",
       "2 -87.620965  \n",
       "3 -87.630524  \n",
       "4 -87.630524  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions = pd.read_csv('transactions_n100000.csv')\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185452, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ Engineer features -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- convert from long to wide\n",
    "df = df_transactions.pivot(\n",
    "    index='ticket_id', columns='item_name', values='item_count').fillna(0)\n",
    "df_transactions.reset_index(inplace=True)\n",
    "df_transactions.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add back date and location\n",
    "df = df.merge(df_transactions[['ticket_id', 'location', 'order_timestamp']\n",
    "                              ].drop_duplicates(), how='left', on='ticket_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- extract hour of day from datetime\n",
    "df['hour'] = df['order_timestamp'].apply(get_hour)\n",
    "#df['hour'] = df['order_timestamp'].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- convert categorical store variables to dummies\n",
    "# use sklearn.preprocessing.OneHotEncoder() to create a class object called encoded_data\n",
    "encoded_data = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(handle_unknown='ignore')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WHAT SHOULD I FIT HERE? \n",
    "\n",
    "# call the method used to fit data for a OneHotEncorder object.\n",
    "# Note: you will have to reshape data from a column of the data frame.\n",
    "# useful functions may be DataFrame methods .to_list(), .reshape(), and .shape()\n",
    "encoded_data.fit(X=np.array(df['location'].tolist()).reshape(df.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed split to regex because not all are 'x0_'\n",
    "col_map_store_binary = dict(zip(list(encoded_data.get_feature_names()), [\n",
    "    'store_' + re.split('x\\d_', x)[1] for x in encoded_data.get_feature_names()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for x in encoded_data.get_feature_names():`\n",
    "\n",
    "    try:\n",
    "\n",
    "        x.split('x0_')[1]\n",
    "\n",
    "    except:\n",
    "\n",
    "        #print(x.split('x0_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix transform data\n",
    "df_store_binary = pd.DataFrame(\n",
    "    encoded_data.fit_transform(df[['location']]).toarray())\n",
    "# df_store_binary = pd.DataFrame(encoded_data.transform(\n",
    "#    X=np.array(df['location'].tolist()).reshape(df.shape[0], 1)))\n",
    "#df_store_binary.head()\n",
    "df_store_binary.columns = encoded_data.get_feature_names()\n",
    "df_store_binary.rename(columns=col_map_store_binary, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_store_binary], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------ RUN CLUSTERING -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- set parameters\n",
    "n_clusters = 3\n",
    "init_point_selection_method = 'k-means++'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- select data\n",
    "# specify list of attributes on which to base clusters\n",
    "cols_for_clustering = ['hour', 'location']\n",
    "\n",
    "# use reindex because loc list is deprecated\n",
    "df_cluster = df.reindex(columns=cols_for_clustering)\n",
    "#df_cluster = df.loc[:, cols_for_clustering]\n",
    "\n",
    "#df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- split to test and train\n",
    "df_cluster_train, df_cluster_test, _, _, = train_test_split(\n",
    "    df_cluster, [1]*df_cluster.shape[0], test_size=0.33)   # ignoring y values for unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fit model\n",
    "attribute_summary_method_dict = {'burger': np.mean, 'fries': np.mean, 'salad': np.mean, 'shake': np.mean, 'hour': np.mean, 'store_1': sum,\n",
    "                                 'store_4': sum, 'store_6': sum, 'store_3': sum, 'store_9': sum, 'store_2': sum, 'store_8': sum, 'store_5': sum, 'store_7': sum}\n",
    "col_output_order = ['burger', 'fries', 'salad', 'shake', 'hour', 'store_1', 'store_2', 'store_3', 'store_4',\n",
    "                    'store_5', 'store_6', 'store_7', 'store_8', 'store_9']  # specify order of output columns for easy of readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SpecificationError",
     "evalue": "nested renamer is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSpecificationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bc68771c308c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_model, train_model_summary = run_kmeans(\n\u001b[0m\u001b[1;32m      3\u001b[0m     n_clusters, init_point_selection_method, df_cluster_train.reindex())\n",
      "\u001b[0;32m<ipython-input-2-d2825be04281>\u001b[0m in \u001b[0;36mrun_kmeans\u001b[0;34m(n_clusters_f, init_f, df_f)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# summarize cluster attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     k_means_model_f_summary = df_f.groupby(\n\u001b[0m\u001b[1;32m     14\u001b[0m         'predict_cluster_kmeans').agg(attribute_summary_method_dict)\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mk_means_model_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_means_model_f_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 ) != len(keys):\n\u001b[0;32m--> 357\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mSpecificationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nested renamer is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSpecificationError\u001b[0m: nested renamer is not supported"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "train_model, train_model_summary = run_kmeans(\n",
    "    n_clusters, init_point_selection_method, df_cluster_train.reindex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "test_model, test_model_summary = run_kmeans(\n",
    "    n_clusters, init_point_selection_method, df_cluster_test.reindex())\n",
    "# all data\n",
    "model, model_summary = run_kmeans(\n",
    "    n_clusters, init_point_selection_method, df_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- run for various number of clusters\n",
    "# add the code to run the clustering algorithm for various numbers of clusters\n",
    "ks = range(1, 16)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    model = KMeans(n_clusters=k, n_init=10)\n",
    "    model.fit(df_cluster)\n",
    "    inertias.append(model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- draw elbow plot\n",
    "# create an elbow plot for your numbers of clusters in previous step\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- output tagged data for examination ----\n",
    "store_col_names = ['store_1', 'store_2', 'store_3', 'store_4',\n",
    "                   'store_5', 'store_6', 'store_7', 'store_8', 'store_9']\n",
    "df_cluster['store'] = None\n",
    "for t_col in store_col_names:\n",
    "    df_cluster.loc[df_cluster[t_col] == 1, 'store'] = t_col.split('_')[1]\n",
    "\n",
    "df_cluster.to_csv('clustering_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign cluster mode to location\n",
    "t_df = df_cluster.groupby('store')['predict_cluster_kmeans'].apply(\n",
    "    lambda x: x.mode()).reset_index()[['store', 'predict_cluster_kmeans']]\n",
    "df_transactions[['location', 'lat', 'long']].drop_duplicates().merge(\n",
    "    t_df, how='left', left_on='location', right_on='store').to_csv('store_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(df['location'].tolist()).reshape(df.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df['location'].tolist()).reshape(df.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bit0209044da7c742dab8314e0953beb93b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
